Amazon Alexa once told user 'Kill your foster parents': Report

A Reuters report has claimed that Amazon's digital assistant Alexa told a customer, "Kill your foster parents" during AI experiments last year. Alexa also reportedly chatted with users about sex acts and dog defecation. Amazon said their AI research aims at making Alexa mimic human banter and users can participate in chatbot trials by saying "let's chat" to their devices.